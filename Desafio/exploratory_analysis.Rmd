---
title: "Análise Exploratória"
format: pdf
editor: visual
---

```{r}
library(knitr)
opts_chunk$set(tidy.opts=list(width.cutoff=60),tidy=TRUE)
```

```{r}
#| warning: false
#| echo: false
library(ggplot2)
library(GGally)
library(dplyr)
library(tibble)
library("RColorBrewer")
library(boot)
library(ggsci)
library("viridis")
library(patchwork)
library(hnp)
library(Epi)
library(car)

```

# Amostragem da base e separação teste/treino

Essa seção faz a amostragem dos conjunto de dados e salva os arquivos resultantes em baseprincipal.csv, basetreino.csv e basetest.csv. Não precisa ser rodada para a análise exploratória.

```{r}
#| echo: false
#data <- read.csv2('coverageX.txt', sep = '\t')
#data
```

```{r}
#| echo: false
#set.seed(10727865)
#sampled_df <- sample_n(data, 2000)
#write.csv(sampled_df,'baseprincipal.csv', sep = '/t', row.names = F)

#sampled_df <- data.frame(sampled_df)

#sampled_df[c(1,2),]
```

```{r}
#| echo: false
#train_idx <- caret::createDataPartition(sampled_df$y, p =0.7, list = FALSE)

#train_df <- sampled_df[train_idx,]
#test_df <- sampled_df[-train_idx,]

#write.csv(train_df,'basetreino.csv', sep = '/t', row.names = F)

#write.csv(test_df,'baseteste.csv', sep = '/t', row.names = F)

```

# Análise Exploratória

## 

## Apresentação dos Dados

Uma das modalidades de seguro de veículos é conhecida como cobertura completa e pode ser acionada para cubrir os custos de danos ao automóvel por qualquer tipo de acidente, colisão, furto, vandalismos, enchentes ou impacto causado por um objeto inanimado. Baseado em um lista de quatro características de possíveis clientes querendo predizer a probabilidade de um indíviduo a cobertura completa. O conjunto de dados é formado por 2000 observações com as seguintes covariáveis:

-   **AGE** - variável inteira, idade em anos dos indivíduos

-   **MEN** - variável binária, sexo dos indivíduos (1- Masculino, 0 - Feminino)

-   **URBAN** - variável binária, área na qual o indivíduo dirige (1 - Área Urbana, 0 - Área Rural)

-   **PRIVATE** - variável binária, forma de utilização do veículo (1 - Privada, 0 - Comercial)

-   **SENIORITY** - variável inteira, tempo de trabalho em uma mesma empresa

-   **y** - variável binária, se o indivíduo adquiriu cobertura completa? (1 - cobertura completa, 0- não adquiriu cobertura completa)

```{r}
data <- read.csv2('basetreino.csv', sep = ',')

data_test <- read.csv2('baseteste.csv', sep = ',')

data_test <- data_test %>%
  mutate_at(vars("URBAN", "MEN", "PRIVATE", "y"), as.factor)


head(data)
```

## Inconsistências

As colunas que podem apresentar algum tipo de inconsistência são Age e Seniority. Um indivíduo não poderia ter mais anos de trabalho em uma mesma empresa do que de vida. Não temos nenhuma observação desse tipo no conjunto de treino.

```{r}
#inconsistência no conjunto de treino
inconsist1_treino <- data %>% 
  filter(SENIORITY > AGE)
inconsist1_treino
```

Encontramos uma inconsistência no conjunto de teste e procedemos a sua deleção.

```{r}



inconsist1_teste <- data_test %>% 
  filter(SENIORITY > AGE)

inconsist1_teste


todel_index <- which(data_test$SENIORITY > data_test$AGE)

data_test <- data_test[-c(todel_index),]
data_test



```

Filtramos também indivíduos menores de idade e encontramos duas observações no conjunto de treino. Não temos informação sobre o país na qual a amostra foi retirada então não podemos concluir sobre a possibilidade dessas observações e procedemos para sua deleção.

```{r}
inconsist2 <- data %>% 
  filter(AGE < 18)

todel_index <- which(data$AGE < 18)
data <- data[-c(todel_index),]

```

Igualmente para o conjunto de teste

```{r}
inconsist2 <- data_test %>% 
  filter(AGE < 18)

todel_index <-which(data_test$AGE < 18)
data_test <- data_test[-c(todel_index),]

```

## Correlações

Inicialmente, fazemos uma análise de correlação para descobrir se as covariáveis possuem alguma forte relação linear entre si (multicolineariedade) ou com a variável resposta.

### Pearson

Aplicamos a correlação de Pearson para identificar correlação linear entre variáveis numéricas.

```{r}
numeric <- c("AGE", "SENIORITY")
df_pearson<- data[, numeric]



correl<- cor(df_pearson, method = 'pearson')

testRes = corrplot::cor.mtest(df_pearson, conf.level = 0.95, method = 'pearson')

corrplot::corrplot(correl, p.mat = testRes$p, addCoef.col ='black',method = 'square', order = 'FPC', type = 'lower', insig = 'blank', number.cex=0.6)
```

Vemos que Seniority e Age possuem uma correlação estatisticamente significante, ou seja, diferente de zero, porém de baixo módulo. Logo multicolinearidade não parece ser um problema para ambas.

### Spearman

Calculamos também o coeficiente de Spearman para identificar correlações monotônicas entre as variáveis. Valores faltantes indicam que a correlação é estatististicamente igual a zero ao nível de 5% de confiança.

```{r, tidy = TRUE}
#| warning: false
numeric <- c("AGE", "SENIORITY", "y", "MEN", "URBAN", "PRIVATE")
df_spearman<- data[, numeric]



correl<- cor(df_spearman, method = 'spearman')

testRes = corrplot::cor.mtest(df_spearman, conf.level = 0.95, method = 'spearman')

corrplot::corrplot(correl, p.mat = testRes$p, addCoef.col ='black',method = 'square', order = 'FPC', type = 'lower', insig = 'blank', number.cex=0.6)
```

De forma geral, as correlações entre as covariáveis ou são fracas ou inexistentes. Em relação a variável resposta, temos que URBAN possui o maior valor em módulo, porém este também indica fraca correlação monotônica.

## Visão Geral dos Dados

Inicialmente, notamos que os dados são relativamente desbalanceados em relação a variável resposta, já que temos mais de 50% de observações para y = 0. As covariáveis binárias também apresentam desbalanceio, sendo caso mais evidente da variável PRIVATE.

```{r}
#| warning: false
library(lares)

freqs_df(data, plot = T)
```

## Distribuição do Seguro por Covariáveis

Nessa seção, avaliamos quantitativamente a relação entre covariáveis e variável resposta.

### Seguro vs Sexo (MEN)

Como apresentado abaixo, a grande maioria dos dados são referentes a homens que não adquiriram o seguro completo. A porcentagem de mulheres é aproximadamente igual entre os grupos, indicando que não parece haver diferença entre a proporção de indivíduos do sexo feminino entre os dois grupos.

```{r}



hist_men <- ggplot(data %>% count(y, MEN) %>%    
         mutate(pct=n/sum(n)),
       aes(as.factor(y), n, fill=as.factor(MEN))) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0(sprintf("%1.1f", pct*100),"%")), position=position_stack(vjust=0.5)) +
scale_fill_manual(guide_legend(title="Sexo"), values = c("#D95F02", "#1B9E77"),labels = c("Feminino","Masculino")) + 
  labs(x = 'Seguro', y = 'Frequência Absoluta', title = "Distribuição do seguro")


hist_men


scatter_age <- ggplot(data, aes(y=y,
                x=AGE, color = as.factor(MEN)), pch = 21) +
geom_point(position="identity", alpha=0.5) +
ylab("Seguro") +
xlab("Idade") +
ggtitle("Distribuição das idades") + 
scale_color_manual(guide_legend(title="Sexo"), values =  c("#D95F02", "#1B9E77"), labels = c("Feminino", "Masculino"))

```

### Seguro vs região onde dirige (URBAN)

A maior parte dos indivíduos dirigem em áreas urbanas e não adquiriram o seguro completo. Por outro lado, não parece haver grande diferença entre a proporção de indivíduos que compraram ou não o seguro completo entre as áreas rural e urbana

```{r}
hist_urban<- ggplot(data %>% count(y, URBAN) %>%    
         mutate(pct=n/sum(n)),
       aes(as.factor(y), n, fill=as.factor(URBAN))) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0(sprintf("%1.1f", pct*100),"%")), position=position_stack(vjust=0.5)) +
scale_fill_manual(guide_legend(title="Região"), values = c("#66A61E", "#666666"), labels = c("Rural","Urbano")) + 
  labs(x = 'Seguro', y = 'Frequência Absoluta', title = "Distribuição do seguro")

hist_urban


scatter_urban <- ggplot(data, aes(y=y,
                x=AGE, color = as.factor(URBAN)), pch = 21) +
geom_point(position="identity", alpha=0.5) +
ylab("Seguro") +
xlab("Idade") +
ggtitle("Distribuição das idades") + 
scale_color_manual(guide_legend(title="Região"), values = c("#66A61E", "#666666"), labels = c("Rural","Urbano")) 

scatter_urban
```

### Seguro vs Uso de Veículo (PRIVATE)

Já para o tipo de uso do veículo, temos que 64.3% dos dados da amostra são de indivíduos que utilizam automóveis privativamente e não adquiriram o seguro completo. Nota-se também que apenas 0.9% dos dados referem-se a indivíduos que possuem veículos para uso comercial e todos eles não adquiriram seguro completo.

```{r}
hist_private<- ggplot(data %>% count(y, PRIVATE) %>%    
         mutate(pct=n/sum(n)),
       aes(as.factor(y), n, fill=as.factor(PRIVATE))) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0(sprintf("%1.1f", pct*100),"%")), position=position_stack(vjust=0.5)) +
scale_fill_manual(guide_legend(title="Privado"), values = c("#7570B3", "#E7298A"), labels = c("Comercial","Privado")) + 
  labs(x = 'Seguro', y = 'Frequência Absoluta', title = "Distribuição do seguro")

hist_private


scatter_private<- ggplot(data, aes(y=y,
                x=AGE, color = as.factor(PRIVATE)), pch = 21) +
geom_point(position="identity", alpha=0.5) +
ylab("Seguro") +
xlab("Idade") +
ggtitle("Distribuição das idades") + 
scale_color_manual(guide_legend(title="Privado"), values = c("#7570B3", "#E7298A"), labels = c("Comercial","Privado"))
scatter_private

#patch_hist <- (hist_men|hist_urban)/hist_private
#patch_hist
#ggsave("graphics/patch_hist.png", patch_hist , width = 12, height = 6, device='png', limitsize = FALSE, dpi= 500, units = "in")
```

Se filtrarmos os indivíduos que usam veículos de forma comercial, também notamos que todos são do sexo masculino.

```{r}
df <- data %>% 
  filter(PRIVATE == 0)
df
```

```{r}

# scatter_private<- ggplot(data, aes(y=y,
#                 x=SENIORITY, color = as.factor(PRIVATE)), pch = 21) +
# geom_point(position="identity", alpha=0.5) +
# ylab("Seguro") +
# xlab("Idade") +
# ggtitle("Distribuição do Seguro") + 
# scale_color_manual(guide_legend(title="Privado"), values = c("#7570B3", "#E7298A"), labels = c("Comercial","Privado"))
# scatter_private
# 
# 
# scatter_urban<- ggplot(data, aes(y=y,
#                 x=SENIORITY, color = as.factor(URBAN)), pch = 21) +
# geom_point(position="identity", alpha=0.5) +
# ylab("Seguro") +
# xlab("Idade") +
# ggtitle("Distribuição da senioridade") + 
# scale_color_manual(guide_legend(title="Privado"), values = c("#7570B3", "#E7298A"), labels = c("Rural","Urbano"))
# scatter_urban
# 
# 
# scatter_men<- ggplot(data, aes(y=y,
#                 x=SENIORITY, color = as.factor(MEN)), pch = 21) +
# geom_point(position="identity", alpha=0.5) +
# ylab("Seguro") +
# xlab("Idade") +
# ggtitle("Distribuição da senioridade") + 
# scale_color_manual(guide_legend(title="Privado"), values = c("#7570B3", "#E7298A"), labels = c("Feminino","Masculino"))
# scatter_men


```

# Modelos Lineares Generalizados (Clássicos)

Nessa seção, temos o objetivo de ajustar o melhor modelo para predizer, dado as informações do indivíduo, se ele possui ou não cobertura completa do seguro.

```{r}
data_reg <- data %>%
  mutate_at(vars("URBAN", "MEN", "PRIVATE", "y"), as.factor)

data_test <- data_test %>%
  mutate_at(vars("URBAN", "MEN", "PRIVATE", "y"), as.factor)
```

## Regressão Logística (GLM com ligação logit)

Começamos ajustando um modelo de regressão logística clássico. Usamos todas as covariáveis possíveis e aplicamos testes de significância aos coeficientes.

```{r}
m0 <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN + PRIVATE,
 family = binomial(link = "logit"), data = data_reg)

summary(m0)


```

O intercepto e o coeficiente de Private são não significativos, mas procederemos para a retirada apenas do segundo.

```{r}
m1_logit <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = "logit"), data = data_reg)
summary(m1_logit)
```

Verificamos agora o ajuste do modelo utilizando os resíduos de quantil. De forma geral, se o modelo faz um bom ajuste dos dados, esperamos que apenas 5% dos pontos se encontrem fora do envelope simulado. Como esse não é o caso de m1_logit, temos um indicativo de o problema não é bem especificado por ele.

```{r}
hnp.fit.modell = hnp(m1_logit, print.on=TRUE, plot=FALSE,
halfnormal=F)
## Binomial model
plot(hnp.fit.modell,main="Modelo Logito",las=1,pch=20,cex=1,col=c(1,1,1,2))
```

Ao analisar a curva ROC, obtemos um valor de 0.785 pra área sob a curva.

```{r}
library(Epi)
Epi::ROC(m1_logit$fitted.values, data$y, plot= "ROC")
```

```{r}
#library("scales")
#brewer.pal(n = 8, name = "Dark2")

 #"#1B9E77" "#D95F02" "#7570B3" "#E7298A" "#66A61E" "#E6AB02"
#"#A6761D" "#666666"
```

## Regressão Logística (Probit, Cauchit, Cloglog, loglog)

### Probit

Ao utlizar a função de ligação probito, temos um modelo com ainda mais pontos foram do envelope simulado e com área sob a curva também de 0.785.

```{r}
m1_probit <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = "probit"), data = data_reg)

hnp.fit.modell = hnp(m1_probit, print.on=TRUE, plot=FALSE,
halfnormal=F)

summary(m1_probit)

## Binomial model
plot(hnp.fit.modell,main="Modelo Probit",las=1,pch=20,cex=1,col=c(1,1,1,2))
Epi::ROC(m1_probit$fitted.values, data$y, plot= "ROC")
```

### Cauchit

Usando a função de ligação Cauchit, temos uma leve melhor na área sob a curva obtendo 0.785, porém continuamos obtendo indicativos de mau ajuste.

```{r}
m1_cauchit <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = "cauchit"), data = data_reg)

hnp.fit.modell = hnp(m1_probit, print.on=TRUE, plot=FALSE,
halfnormal=F)

summary(m1_cauchit)

## Binomial model
plot(hnp.fit.modell,main="Modelo Cauchit",las=1,pch=20,cex=1,col=c(1,1,1,2))
Epi::ROC(m1_cauchit$fitted.values, data$y, plot= "ROC")
```

### Cloglog

Para a função de ligação Cloglog, temos uma área sob a curva menor e indicativo de mau ajuste.

```{r}
m1_cloglog <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = "cloglog"), data = data_reg)

hnp.fit.modell = hnp(m1_cloglog, print.on=TRUE, plot=FALSE,
halfnormal=F)

#summary(m1_cloglog)

## Binomial model
plot(hnp.fit.modell,main="Modelo Cloglog",las=1,pch=20,cex=1,col=c(1,1,1,2))
Epi::ROC(m1_cloglog$fitted.values, data$y, plot= "ROC")
```

### 

### Loglog

O modelo com função de ligação loglog também recai no problema de mau ajuste e seu desempenho preditivo é apresentado mais adiante.

```{r}

# Geradora para a função de ligação loglog
loglog <- function( ) structure(list(
linkfun = function(mu) -log(-log(mu)),
linkinv = function(eta)
pmax(pmin(exp(-exp(-eta)), 1 - .Machine$double.eps),
.Machine$double.eps),
mu.eta = function(eta) {
eta <- pmin(eta, 700)
pmax(exp(-eta - exp(-eta)), .Machine$double.eps)
},
dmu.deta = function(eta)
pmax(exp(-exp(-eta) - eta) * expm1(-eta),
.Machine$double.eps),
valideta = function(eta) TRUE,
name = "loglog"
), class = "link-glm")

m1_loglog <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = loglog()), data = data_reg)

#hnp.fit.modell = hnp(m1_loglog, print.on=TRUE, plot=FALSE,
#halfnormal=F)

summary(m1_loglog)

## Binomial model
plot(hnp.fit.modell,main="Modelo Cloglog",las=1,pch=20,cex=1,col=c(1,1,1,2))
Epi::ROC(m1_loglog$fitted.values, data$y, plot= "ROC")
```

### AIC

```{r}
# Dataframe para verificar o AIC
data.frame(Modelo=c("Modelo logito","Modelo probito","Modelo cauchito","Modelo cloglog","Modelo loglog"),
AIC = c(AIC(m1_logit),AIC(m1_probit),AIC(m1_cauchit),
AIC(m1_cloglog), AIC(m1_loglog)))
```

Comparando os modelos pelo critério de Akaike, temos que o modelo loglog tende o mais balanceado em relação a qualidade de ajuste e quantidade de parâmetros. Contudo, como todos os outros modelos ajustados, temos fortes indicativos de um mau ajuste evidenciado pelos gráficos de envelope simulado. Prosseguiremos para a análise de influência e alavancagem dos pontos.

## Retirada de pontos influentes Loglog

O gráfico em azul apresenta a distância de Cook para identificar pontos influentes. O segundo gráfico mostra os resíduos studentizados e a tabela apresenta informações de alguns pontos apontados como outlier usando o teste de Bonferroni para outliers.

```{r}
#plot(m1_loglog)
influenceIndexPlot(m1_loglog,col='blue')
influencePlot(m1_loglog)
```

Pelos valores de resíduos studentizados, temos que os pontos 771 e 1400 encontram-se foram do intervalor (-2,2).

Para avaliar a alavancagem, procuramos valores de Hat superiores a 2\*p/n = 0,007. Assim, concluimos que os pontos 529 e 665 apresentam indícios de impactarem nas predições do modelo. Como esses pontos também foram postos em evidência pela distância de Cook, vamos verificar o impacto de sua retirada.

Ajustamos um modelo considerando a retirada de cada ponto e um modelo considerando a remoção de ambos.

```{r}

ajuste1 <- glm(formula = y ~URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = loglog()), subset = -c(529) , data = data_reg)

ajuste2 <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = loglog()), subset = -c(665) , data = data_reg)

ajuste3 <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = loglog()), subset = -c(529,665) , data = data_reg)


compareCoefs(m1_loglog,ajuste1, ajuste2, ajuste3)

```

Ao comparar os coeficientes entre os modelos não notamos diferenças significativas entre os coeficientes. Vejamos o impacto no AIC:

```{r}
data.frame(
Modelo= c("Completo", "Removendo 529", "Removendo 665",
"Removendo 529 e 665"),
AIC = c(AIC(m1_loglog),AIC(ajuste1), AIC(ajuste2), AIC(ajuste3)))
```

Nota-se que o AIC diminui com a retirada de ambos os pontos. Sem uma base teórica que justifique a retirada desses pontos, não podemos simplesmente excluí-los da análise. Porém, vamos seguir utilizando o modelo reduzido para testar seu desempenho no conjunto de teste.

## Acurácia no conjunto de teste

A seguir,testamos o poder de predição dos modelos loglog com o conjunto de dados completo e reduzido. Aplicamos novamente a curva ROC e calculamos o F1-Score dos algoritmos, assim podemos ter uma ideia de como as predições

```{r}
accuracy <- function(model, model_roc, test_df) {
  
  #use roc returned by Epi roc function
  
  thresh_index <- which.max(rowSums(model_roc$res[, c("sens", "spec")]))
  
  recall <- model_roc$res[thresh_index,][1,1]
  precision <- model_roc$res[thresh_index,][1,3]

  f1_score <- 2*(recall*precision)/(recall+precision)
  
  
  thresh <- as.double(rownames(model_roc$res[thresh_index,][1]))
  predict_test <- ifelse(predict(model, newdata = test_df, type = 'response') >= thresh, 1,0)
  
  acc <- mean(predict_test == test_df$y)
  
  return(c(acc,precision, recall,f1_score))
  
}
```

```{r}
y_pred <- predict(ajuste3,newdata = data_test, type = 'response')
roc_logit <- Epi::ROC(y_pred, data_test$y, plot= T)

logitr_res_test <- accuracy(ajuste3, roc_logit, data_test )
logitr_acc_test <- logitr_res_test[1]
logitr_f1_test<-  logitr_res_test[4]
logitr_precision_test <- logitr_res_test[2]
logitr_recall_test <- logitr_res_test[3]
```

```{r}
## loglog model
y_pred <- predict(m1_loglog,newdata = data_test, type = 'response')
roc_loglog <- Epi::ROC(y_pred, data_test$y, plot= F)

loglog_res_test <- accuracy(m1_loglog, roc_loglog, data_test )
loglog_acc_test <- loglog_res_test[1]
loglog_f1_test<-  loglog_res_test[4]
loglog_precision_test <- loglog_res_test[2]
loglog_recall_test <- loglog_res_test[3]
```

```{r}

# Load the required libraries
library(formattable)

# Create a data frame with the data
data <- data.frame(
  Modelo = c("Modelo loglog", "Modelo loglog Reduzido"),
  'Acurácia' = c(loglog_acc_test, logitr_acc_test),
  'Precisão' = c(loglog_precision_test, logitr_precision_test),
  'Recall' = c(loglog_recall_test, logitr_recall_test),
  
 'F1Score' = c(loglog_f1_test, logitr_f1_test)
)

# Create a formattable
ft <- formattable(data,
                  align = c("l", "r", "r") # Set alignment for each column
)

# Print the formattable
print(ft)

```

# Random Forest

```{r}
library(randomForest)
```

O algoritmo de RandomForest trata-se de uma combinação de árvores de classificação. Os resultados gerados em diferentes árvores são posteriomente agregados em um único, de forma a reduzir a chance de superajuste (overfitting) e aumentar a acurácia.

Inicialmente, usamos a função tuneRF para encontrar o valor de mtry (número de variáveis aleatoriamente amostradas para ajustar as árvores).

```{r}
t <- tuneRF(data_reg[,-1], data_reg[,1],
       stepFactor = 0.5,
       plot = TRUE,
       ntreeTry = 150,
       trace = TRUE,
       improve = 0.05)
```

Usando mtry = 2, usamos randomForest para ajustar o modelo.

```{r}
rf <- randomForest(y~., data=data_reg, proximity=TRUE, mtry = 2) 
print(rf)
#plot(rf)
```

No conjunto de treino, temos um taxa de erro de 31.29%, vemos também que o modelo tende a errar mais para indivíduos que possuem cobertura completa do seguro. Vejamos o desempenho do modelo no conjunto de treino:

```{r}
p2 <- predict(rf, data_test)
cf_test <- caret::confusionMatrix(p2, data_test$y)
cf_test
acc_rf <- cf_test$overall[1]


#f1 score
#recall or sensitity/ recall or PPV
recall <- as.double(cf_test$byClass[1])
precision <- as.double(cf_test$byClass[3])

f1_rf <- 2*(recall*precision)/(precision+recall)
```

Temos uma acurácia de 0.72 e um F1-Score de 0.78.

```{r}
#hist(treesize(rf),
#     main = "No. of Nodes for the Trees",
#     col = "green")
varImpPlot(rf,
           sort = T,
           n.var = 4,
           main = "Top 10 - Variable Importance")
importance(rf)
```

```{r}
knitr::knit_exit()
```

# Soluções Bayesianas

## Modelo Cauchit

A seguir, ajustaremos um modelo linear generalizado bayesiano com função de ligação de potência inversa.

$$
Y_i |\beta,\delta \sim Bernoulli(F(x_i\beta))
\beta \sim N(0,100)
\delta \sim Uniforme(-2,2)
\lambda = \exp(\delta)
$$

Como utilizamos um método de

```{r}
modelString="
model{
  for (i in 1:N) {
    y[i] ~ dbern(p[i])
    m[i] <- beta0+beta_urban*URBAN[i] + beta_sen*SEN[i] + beta_age*AGE[i] + beta_men*MEN[i]
    pstar[i] <- 1/3.141592* arctan(-m[i]) + 1/2
    p[i] <- 1-pow(pstar[i], lambda)
  
  }
  beta0 ~ dnorm(0,100)
  delta ~ dunif(-2,2)
  lambda <- exp(delta)
  beta_urban ~ dnorm(0,100)
  beta_sen ~ dnorm(0,100)
  beta_age ~ dnorm(0,100)
  beta_men ~ dnorm(0,100)
  
  }

"
writeLines(modelString, con='models/m1_cauchit.bug')
```

```{r}
N = nrow(data)
jagsData <- list(N = N, y = data$y,
    URBAN = data$URBAN, SEN = data$SENIORITY, 
    AGE = data$AGE, MEN = data$MEN)
```

```{r}
m1_blogit <- jags(data=jagsData,model.file='models/m1_cauchit.bug',
                   param=c('beta0','beta_urban', 'beta_sen', 'beta_age', 'beta_men', 'lambda'),
                   n.chains=3, n.iter=30000, n.burnin=5000, n.thin=10)
```

```{r}
mcmc.samples <- as.mcmc(m1_blogit)
```

```{r}
library(lattice)

jagsfit.mcmc <- as.mcmc(m1_blogit)
densityplot(mcmc.samples)

HPDinterval(jagsfit.mcmc)
traceplot(jagsfit.mcmc)

```

## Predição nos conjuntos de treino e teste

```{r}
#| warning: false

predict_bcauchit <- function(jagsfit.mcmc, data) {
# data deve ser do tipo dataframe

#vetor da média dos coeficientes beta_age/beta_men/beta_sen/beta_urban
coef <- as.matrix(summary(jagsfit.mcmc)$statistics[, 'Mean'][1:5])
lambda <- as.matrix(summary(jagsfit.mcmc)$statistics[, 'Mean'])[7]


data_matrix <- data.matrix(data)[,c(-1,-4)][, c(3,1,4,2)]
data_matrix <- cbind(data_matrix, intercept = 1)
n <- dim(data_matrix)[1]


#coef * data
res <- t(coef) %*% t(data_matrix)
res_vec <- as.vector(res)


pstar <- 1/pi* atan(-res_vec) + 0.5
p <- 1- pstar^lambda

predictions <- rbinom(n, 1, p)

return(predictions)
}


accuracy_bayes <- function(model_roc, test_df, predict) {
  
  #use roc returned by Epi roc function
  
  thresh_index <- which.max(rowSums(model_roc$res[, c("sens", "spec")]))
  
  recall <- model_roc$res[thresh_index,][1,1]
  precision <- model_roc$res[thresh_index,][1,3]

  f1_score <- 2*(recall*precision)/(recall+precision)
  
  
  thresh <- as.double(rownames(model_roc$res[thresh_index,][1]))
  
  
  acc <- mean(predict == test_df$y)
  
  return(c(acc,precision, recall,f1_score))
  
}

roc_bayes <- Epi::ROC(pred_train, data$y, plot= F)
accuracy_bayes(ajuste3, roc_bayes, data, pred_train )


```
