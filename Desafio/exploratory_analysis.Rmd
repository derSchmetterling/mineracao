---
title: "Análise Exploratória"
format: pdf
editor: visual
---

```{r}
#: warning: false
#| echo: false
library(ggplot2)
library(GGally)
library(dplyr)
library(tibble)
library("RColorBrewer")
library(boot)
library(ggsci)
library("viridis")
library(patchwork)
library(hnp)
library(Epi)
library(car)

```

# 

# Amostragem da base e separação teste/treino

Essa seção faz a amostragem dos conjunto de dados e salva os arquivos resultantes em baseprincipal.csv, basetreino.csv e basetest.csv. Não precisa ser rodada para a análise exploratória.

```{r}
#| echo: false
#data <- read.csv2('coverageX.txt', sep = '\t')
#data
```

```{r}
#| echo: false
#set.seed(10727865)
#sampled_df <- sample_n(data, 2000)
#write.csv(sampled_df,'baseprincipal.csv', sep = '/t', row.names = F)

#sampled_df <- data.frame(sampled_df)

#sampled_df[c(1,2),]
```

```{r}
#| echo: false
#train_idx <- caret::createDataPartition(sampled_df$y, p =0.7, list = FALSE)

#train_df <- sampled_df[train_idx,]
#test_df <- sampled_df[-train_idx,]

#write.csv(train_df,'basetreino.csv', sep = '/t', row.names = F)

#write.csv(test_df,'baseteste.csv', sep = '/t', row.names = F)

```

# Análise Exploratória

## 

## Apresentação dos Dados

Uma das modalidades de seguro de veículos é conhecida como cobertura completa e pode ser acionada para cubrir os custos de danos ao automóvel por qualquer tipo de acidente, colisão, furto, vandalismos, enchentes ou impacto causado por um objeto inanimado. Baseado em um lista de quatro características de possíveis clientes querendo predizer a probabilidade de um indíviduo a cobertura completa. O conjunto de dados é formado por 2000 observações:

-   **AGE** - variável inteira, idade em anos dos indivíduos

-   **MEN** - variável binária, sexo dos indivíduos (1- Masculino, 0 - Feminino)

-   **URBAN** - variável binária, se o indivíduo dirige em 1 - área urbana, 0 - área rural

-   **PRIVATE** - variável binária, o veículo é utilizado de forma 1 - privada, 0 - outra forma

-   **SENIORITY** - variável inteira, tempo de uso da carteira de motorista

-   **y** - variável binária, o indivíduo adquiriu cobertura completa? 1 - cobertura completa, 0- não adquiriu cobertura completa

```{r}
data <- read.csv2('basetreino.csv', sep = ',')

data_test <- read.csv2('baseteste.csv', sep = ',')

data_test <- data_test %>%
  mutate_at(vars("URBAN", "MEN", "PRIVATE", "y"), as.factor)

data_reg <- data %>%
  mutate_at(vars("URBAN", "MEN", "PRIVATE", "y"), as.factor)

head(data)
```

## Correlações

Inicialmente, fazemos uma análise de correlação para descobrir se as covariáveis possuem alguma forte relação linear entre si (multicolineariedade) ou com a variável resposta.

### Pearson

```{r}
numeric <- c("AGE", "SENIORITY")
df_pearson<- data[, numeric]



correl<- cor(df_pearson, method = 'pearson')

testRes = corrplot::cor.mtest(df_pearson, conf.level = 0.95, method = 'pearson')

corrplot::corrplot(correl, p.mat = testRes$p, addCoef.col ='black',method = 'square', order = 'FPC', type = 'lower', insig = 'blank', number.cex=0.6)
```

### Spearman

```{r}
#| warning: false
numeric <- c("AGE", "SENIORITY", "y", "MEN", "URBAN", "PRIVATE")
df_spearman<- data[, numeric]



correl<- cor(df_spearman, method = 'spearman')

testRes = corrplot::cor.mtest(df_spearman, conf.level = 0.95, method = 'spearman')

corrplot::corrplot(correl, p.mat = testRes$p, addCoef.col ='black',method = 'square', order = 'FPC', type = 'lower', insig = 'blank', number.cex=0.6)
```

## Distribuição do Seguro por Covariáveis

### Seguro vs Sexo (MEN)

```{r}



hist_men <- ggplot(data %>% count(y, MEN) %>%    
         mutate(pct=n/sum(n)),
       aes(as.factor(y), n, fill=as.factor(MEN))) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0(sprintf("%1.1f", pct*100),"%")), position=position_stack(vjust=0.5)) +
scale_fill_manual(guide_legend(title="Sexo"), values = c("#D95F02", "#1B9E77"),labels = c("Feminino","Masculino")) + 
  labs(x = 'Seguro', y = 'Frequência Absoluta', title = "Distribuição do seguro")


hist_men


scatter_age <- ggplot(data, aes(y=y,
                x=AGE, color = as.factor(MEN)), pch = 21) +
geom_point(position="identity", alpha=0.5) +
ylab("Seguro") +
xlab("Idade") +
ggtitle("Distribuição das idades") + 
scale_color_manual(guide_legend(title="Sexo"), values =  c("#D95F02", "#1B9E77"), labels = c("Feminino", "Masculino"))

```

### Seguro vs região onde dirige (URBAN)

```{r}
hist_urban<- ggplot(data %>% count(y, URBAN) %>%    
         mutate(pct=n/sum(n)),
       aes(as.factor(y), n, fill=as.factor(URBAN))) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0(sprintf("%1.1f", pct*100),"%")), position=position_stack(vjust=0.5)) +
scale_fill_manual(guide_legend(title="Região"), values = c("#66A61E", "#666666"), labels = c("Rural","Urbano")) + 
  labs(x = 'Seguro', y = 'Frequência Absoluta', title = "Distribuição do seguro")

hist_urban


scatter_urban <- ggplot(data, aes(y=y,
                x=AGE, color = as.factor(URBAN)), pch = 21) +
geom_point(position="identity", alpha=0.5) +
ylab("Seguro") +
xlab("Idade") +
ggtitle("Distribuição das idades") + 
scale_color_manual(guide_legend(title="Região"), values = c("#66A61E", "#666666"), labels = c("Rural","Urbano")) 

scatter_urban
```

### Seguro vs Uso de Veículo (PRIVATE)

```{r}
hist_private<- ggplot(data %>% count(y, PRIVATE) %>%    
         mutate(pct=n/sum(n)),
       aes(as.factor(y), n, fill=as.factor(PRIVATE))) +
  geom_bar(stat="identity") +
  geom_text(aes(label=paste0(sprintf("%1.1f", pct*100),"%")), position=position_stack(vjust=0.5)) +
scale_fill_manual(guide_legend(title="Privado"), values = c("#7570B3", "#E7298A"), labels = c("Comercial","Privado")) + 
  labs(x = 'Seguro', y = 'Frequência Absoluta', title = "Distribuição do seguro")

hist_private


scatter_private<- ggplot(data, aes(y=y,
                x=AGE, color = as.factor(PRIVATE)), pch = 21) +
geom_point(position="identity", alpha=0.5) +
ylab("Seguro") +
xlab("Idade") +
ggtitle("Distribuição das idades") + 
scale_color_manual(guide_legend(title="Privado"), values = c("#7570B3", "#E7298A"), labels = c("Comercial","Privado"))
scatter_private

#patch_hist <- (hist_men|hist_urban)/hist_private
#patch_hist
#ggsave("graphics/patch_hist.png", patch_hist , width = 12, height = 6, device='png', limitsize = FALSE, dpi= 500, units = "in")
```

```{r}

scatter_private<- ggplot(data, aes(y=y,
                x=SENIORITY, color = as.factor(PRIVATE)), pch = 21) +
geom_point(position="identity", alpha=0.5) +
ylab("Seguro") +
xlab("Idade") +
ggtitle("Distribuição da senioridade") + 
scale_color_manual(guide_legend(title="Privado"), values = c("#7570B3", "#E7298A"), labels = c("Comercial","Privado"))
scatter_private


scatter_urban<- ggplot(data, aes(y=y,
                x=SENIORITY, color = as.factor(URBAN)), pch = 21) +
geom_point(position="identity", alpha=0.5) +
ylab("Seguro") +
xlab("Idade") +
ggtitle("Distribuição da senioridade") + 
scale_color_manual(guide_legend(title="Privado"), values = c("#7570B3", "#E7298A"), labels = c("Rural","Urbano"))
scatter_urban


scatter_men<- ggplot(data, aes(y=y,
                x=SENIORITY, color = as.factor(MEN)), pch = 21) +
geom_point(position="identity", alpha=0.5) +
ylab("Seguro") +
xlab("Idade") +
ggtitle("Distribuição da senioridade") + 
scale_color_manual(guide_legend(title="Privado"), values = c("#7570B3", "#E7298A"), labels = c("Feminino","Masculino"))
scatter_men


```

# Modelos

## Regressão Logística (GLM com ligação logit)

No modelo m0, private é não significativo, porém ao testar o modelo m1 e o m2, private parece reduzir a desviância.

```{r}
m0 <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN + PRIVATE,
 family = binomial(link = "logit"), data = data_reg)

m1_logit <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = "logit"), data = data_reg)

m2 <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN + PRIVATE,
 family = binomial(link = "logit"), data = data_reg)

summary(m0)
anova(m0,m1, test = 'Chisq')
```

```{r}
library(Epi)
ROC(m1$fitted.values, data$y, plot= "ROC")
```

```{r}
hnp.fit.modell = hnp(m1, print.on=TRUE, plot=FALSE,
halfnormal=F)
## Binomial model
plot(hnp.fit.modell,main="Modelo Logito",las=1,pch=20,cex=1,col=c(1,1,1,2))
```

```{r}
#library("scales")
#brewer.pal(n = 8, name = "Dark2")

 #"#1B9E77" "#D95F02" "#7570B3" "#E7298A" "#66A61E" "#E6AB02"
#"#A6761D" "#666666"
```

## Regressão Logística (Probit, Cauchit, Cloglog, loglog)

### Probit

```{r}
m1_probit <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = "probit"), data = data_reg)

hnp.fit.modell = hnp(m1_probit, print.on=TRUE, plot=FALSE,
halfnormal=F)

summary(m1_probit)

## Binomial model
plot(hnp.fit.modell,main="Modelo Probit",las=1,pch=20,cex=1,col=c(1,1,1,2))
ROC(m1_probit$fitted.values, data$y, plot= "ROC")
```

### Cauchit

```{r}
m1_cauchit <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = "cauchit"), data = data_reg)

hnp.fit.modell = hnp(m1_probit, print.on=TRUE, plot=FALSE,
halfnormal=F)

summary(m1_cauchit)

## Binomial model
plot(hnp.fit.modell,main="Modelo Cauchit",las=1,pch=20,cex=1,col=c(1,1,1,2))
ROC(m1_cauchit$fitted.values, data$y, plot= "ROC")
```

### Cloglog

```{r}
m1_cloglog <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = "cloglog"), data = data_reg)

hnp.fit.modell = hnp(m1_cloglog, print.on=TRUE, plot=FALSE,
halfnormal=F)

summary(m1_cloglog)

## Binomial model
plot(hnp.fit.modell,main="Modelo Cloglog",las=1,pch=20,cex=1,col=c(1,1,1,2))
ROC(m1_cloglog$fitted.values, data$y, plot= "ROC")
```

### 

### Loglog

Como ver gráfico para loglog

```{r}


# Geradora para a função de ligação loglog
loglog <- function( ) structure(list(
linkfun = function(mu) -log(-log(mu)),
linkinv = function(eta)
pmax(pmin(exp(-exp(-eta)), 1 - .Machine$double.eps),
.Machine$double.eps),
mu.eta = function(eta) {
eta <- pmin(eta, 700)
pmax(exp(-eta - exp(-eta)), .Machine$double.eps)
},
dmu.deta = function(eta)
pmax(exp(-exp(-eta) - eta) * expm1(-eta),
.Machine$double.eps),
valideta = function(eta) TRUE,
name = "loglog"
), class = "link-glm")

m1_loglog <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = loglog()), data = data_reg)

#hnp.fit.modell = hnp(m1_loglog, print.on=TRUE, plot=FALSE,
#halfnormal=F)

summary(m1_loglog)

## Binomial model
plot(hnp.fit.modell,main="Modelo Cloglog",las=1,pch=20,cex=1,col=c(1,1,1,2))
ROC(m1_loglog$fitted.values, data$y, plot= "ROC")
```

### AIC

```{r}
# Dataframe para verificar o AIC
data.frame(Modelo=c("Modelo logito","Modelo probito","Modelo cauchito","Modelo cloglog","Modelo loglog"),
AIC = c(AIC(m1),AIC(m1_probit),AIC(m1_cauchit),
AIC(m1_cloglog), AIC(m1_loglog)))

```

O modelo loglog é o que apresenta menor AIC, porém, como todos os outros, temos fortes indicativos de um mau ajuste ao olhar o QQPlot.

#### Retira de pontos influentes Loglog

```{r}
plot(m1_loglog)

influenceIndexPlot(m1_loglog,col='blue')
```

```{r}
influencePlot(m1_loglog)
```

Pelos valores de resíduos studentizados, temos que os pontos 771 e 1400 encontram-se foram do intervalor (-2,2). Para avaliar a alavancagem, procuramos valores de Hat tais que $h > \frac{2p}{n} = \frac{10}{1400} = 0,007$

Assim, chegamos que os pontos 529 e 665. Como esses pontos também foram postos em evidência pela distância de Cook, vamos verificar o impacto de sua retirada.

```{r}

ajuste1 <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = loglog()), subset = -c(529) , data = data_reg)

ajuste2 <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = loglog()), subset = -c(665) , data = data_reg)

ajuste3 <- glm(formula = y ~  URBAN + SENIORITY+ AGE + MEN,
 family = binomial(link = loglog()), subset = -c(529,665) , data = data_reg)


compareCoefs(m1_loglog,ajuste1, ajuste2, ajuste3)

```

```{r}
data.frame(
Modelo= c("Completo", "Removendo 529", "Removendo 665",
"Removendo 529 e 665"),
AIC = c(AIC(m1_loglog),AIC(ajuste1), AIC(ajuste2), AIC(ajuste3)))
```

Nota-se que o AIC diminui com a retirada de ambos os pontos, porém como não podemos simplesmente retirá-los sem permissão do pesquisador, vamos sugerir dois modelos: 1 reduzido e 1 completo.

## Acurácia no conjunto de teste

```{r}
accuracy <- function(model, model_roc, test_df) {
  
  #use roc returned by Epi roc function
  
  thresh_index <- which.max(rowSums(model_roc$res[, c("sens", "spec")])) 
  thresh <- as.double(rownames(model_roc$res[thresh_index,][1]))
  predict_test <- ifelse(predict(model, newdata = test_df, type = 'response') > thresh, 1,0)
  
  acc <- mean(predict_test == test_df$y)
  
  return(acc)
  
}
```

```{r}
## Cloglog model
y_pred <- predict(m1_logit,newdata = data_test, type = 'response')
roc_logit <- ROC(y_pred, data_test$y, plot= "ROC")

logit_acc_train <- accuracy(m1_logit, roc_logit, data_test )

```

```{r}
## probit model
y_pred <- predict(m1_probit,newdata = data_test, type = 'response')
roc_probit <- ROC(y_pred, data_test$y, plot= "ROC")

probit_acc_train <- accuracy(m1_probit, roc_probit, data_test )
```

```{r}
## Cloglog model
y_pred <- predict(m1_loglog,newdata = data_test, type = 'response')
roc_loglog <- ROC(y_pred, data_test$y, plot= "ROC")

loglog_acc_train <- accuracy(m1_loglog, roc_loglog, data_test )
```

```{r}
## cauchit model
y_pred <- predict(m1_cauchit,newdata = data_test, type = 'response')
roc_cauchit <- ROC(y_pred, data_test$y, plot= "ROC")

cauchit_acc_train <- accuracy(m1_cauchit, roc_cauchit, data_test )
```

```{r}
## Cloglog model
y_pred <- predict(m1_cloglog,newdata = data_test, type = 'response')
roc_cloglog <- ROC(y_pred, data_test$y, plot= "ROC")

cloglog_acc_train <- accuracy(m1_cloglog, roc_cloglog, data_test )


```

```{r}
# Dataframe para verificar o AIC
data.frame(Modelo=c("Modelo logito","Modelo probito","Modelo cauchito","Modelo cloglog","Modelo loglog"),
AIC = c(AIC(m1),AIC(m1_probit),AIC(m1_cauchit),
AIC(m1_cloglog), AIC(m1_loglog)),
'Acurácia Teste' = c(logit_acc_train,probit_acc_train,cauchit_acc_train,
cloglog_acc_train, loglog_acc_train))
```

```{r}

# Load the required libraries
library(formattable)

# Create a data frame with the data
data <- data.frame(
  Modelo = c("Modelo logit", "Modelo probit", "Modelo cauchit", "Modelo cloglog", "Modelo loglog"),
  AIC =  c(AIC(m1),AIC(m1_probit),AIC(m1_cauchit),
AIC(m1_cloglog), AIC(m1_loglog)),
  Acuracia_Teste = c(logit_acc_train,probit_acc_train,cauchit_acc_train,
cloglog_acc_train, loglog_acc_train)
)

# Create a formattable
ft <- formattable(data,
                  align = c("l", "r", "r") # Set alignment for each column
)

# Print the formattable
print(ft)

```

## Soluções Bayesianas

### Modelo Logito

```{r}
#library(rjags)
library(R2jags)

modelString="
model{
  for (i in 1:N) {
    y[i] ~ dbern(p[i])
    logit(p[i]) <- beta0+beta_urban*URBAN[i] + beta_sen*SEN[i] + beta_sen*AGE[i] + beta_men*MEN[i]
  }
  beta0 ~ dnorm(0,100)
  delta ~ duniform(-2,2)
  beta_urban ~ dnorm(0,100)
  beta_sen ~ dnorm(0,100)
  beta_age ~ dnorm(0,100)
  beta_men ~ dnorm(0,100)
}
"
writeLines(modelString, con='models/m1_logit.bug')


```

```{r}
N = nrow(data)
jagsData <- list(N = N, y = data$y,
    URBAN = data$URBAN, SEN = data$SENIORITY, 
    AGE = data$AGE, MEN = data$MEN)
```

```{r}
m1_blogit <- jags(data=jagsData,model.file='models/m1_logit.bug',
                   param=c('beta0','beta_urban', 'beta_sen', 'beta_age', 'beta_men' ),
                   n.chains=3, n.iter=20000, n.burnin=5000, n.thin=10)
```

```{r}
#Solucoes bayesianas
####################
attach(data_reg)
#usando MCMCpack
if(!require(MCMCpack)) install.packages("MCMCpack")
library(MCMCpack)
# Con una distribucion a priori impropia
formula=y~MEN+URBAN+PRIVATE+AGE+SENIORITY
mlMCMCpack <- MCMClogit(formula,
                        burnin=5000, mcmc=10000)
summary(mlMCMCpack)
plot(mlMCMCpack)


# diagnostics
chain <- autocorr.diag(mlMCMCpack)
autocorr.plot(mlMCMCpack, lag.max = 100)

#batchSE(mlMCMCpack)
#HPDinterval(mlMCMCpack)
#crosscorr.plot(mlMCMCpack)
#traceplot(mlMCMCpack)
#densplot(mlMCMCpack)
#help(MCMClogit)
```

```{r}
# Thus, we have a distribution of model predictions for each x
predict.p.mcmc <- function(x) 1 / (1 + exp(-mlMCMCpack %*% rbind(1,x)))
interval.p.mcmc <- function(x, low, high) apply(predict.p.mcmc(x), 2,
                                                function(x) quantile(x, c(low, high)))

predict.y.mcmc <- function(x) mlMCMCpack %*% rbind(1,x)
interval.y.mcmc <- function(x, low, high) apply(predict.y.mcmc(x), 2,
                                                function(x) quantile(x, c(low, high)))

## Plot the data and fits ##

x = data_reg[, c("MEN", "URBAN", "PRIVATE", "AGE", "SENIORITY")]
y = data_reg[, "y"]

plot(x, y, pch = 20, cex = 0.5, main = 'Probability vs x')
```

```{r}
#arm
if(!require(arm)) install.packages("arm")
library(arm)
mlarm <- bayesglm(formula, family=binomial(link="power"), 
                        prior.scale=Inf, prior.df=Inf)
summary(mlarm)

?bayesglm


chain <- autocorr.diag(mlarm)
autocorr.plot(mlarm, lag.max = 100)

batchSE(mlarm)
HPDinterval(mlarm)
crosscorr.plot(mlarm)
traceplot(mlarm)
densplot(mlarm)

```

```{r}
#| warning: false



#inla
#install.packages("INLA", repos<-"http://www.math.ntnu.no/inla/R/stable")
require(INLA)
install.packages('INLA')
mlinla<-inla(formula =formula, family = "binomial", data = coverage, control.family=list(link='logit'),
control.compute = list(dic=TRUE),control.predictor = list(compute=TRUE))
summary(mlinla)
mlinla$dic$dic
#DIC=4301.899

#codigo para ajustar o modelo skew probito 
#Bazán, J. L. , Bolfarine, H. y Branco, D. M. (2010) A framework for skew-probit links in Binary regression. 
#Communications in Statistics - Theory and Methods, 39, 678-697.

spinla<-inla(formula =formula, family = "binomial", data = coverage, 
             control.family = list(
               control.link = list(
                 model = "sn",
                 hyper = list(alpha = list(
                   prior = "normal",
                   initial = 0,
                   param = c(mean=0.0,prec=0.001),
                   fixed=FALSE)))),
             control.compute = list(dic=TRUE),
             control.predictor = list(compute=TRUE))
summary(spinla)
spinla$dic$dic
#DIC=4254.631
#Conclusão: O modelo skewprobito é um melhor
#modelo para estes dados do que o modelo logístico
#porque os dados são desbalanceados.


#Na estimação bayesianao, usamos DIC (Deviance Information
#Crieria) para comparar modelos alternativos
#quando o DIC é menor, então o modelo é melhor.

```
