---
title: "Modelos Alternativos"
author: "Pedro Vinicius Alves"
date: "2023-04-11"
output: pdf_document
---



```{r setup, include=FALSE}

#: warning: false
#| echo: false

library(randomForest)
library(dplyr)
library(R2jags)
library(coda)
```

## Leitura dos Dados


```{r cars}
data <- read.csv2('basetreino.csv', sep = ',')

data_test <- read.csv2('baseteste.csv', sep = ',')

data_test <- data_test %>%
  mutate_at(vars("URBAN", "MEN", "PRIVATE", "y"), as.factor)

data_reg <- data %>%
  mutate_at(vars("URBAN", "MEN", "PRIVATE", "y"), as.factor)

head(data)
```

### Reversal Power Links

```{r}
modelString="
model{
  for (i in 1:N) {
    y[i] ~ dbern(p[i])
    m[i] <- beta0+beta_urban*URBAN[i] + beta_sen*SEN[i] + beta_age*AGE[i] + beta_men*MEN[i]
    pstar[i] <- 1/(1+exp(-m[i]))
    p[i] <- pow(pstar[i], lambda)
  
  }
  beta0 ~ dnorm(0,100)
  delta ~ dunif(-2,2)
  lambda <- exp(delta)
  beta_urban ~ dnorm(0,100)
  beta_sen ~ dnorm(0,100)
  beta_age ~ dnorm(0,100)
  beta_men ~ dnorm(0,100)
  
  }

"
writeLines(modelString, con='models/m1_logit.bug')
```


```{r}
power(2,3)
```


```{r}
N = nrow(data)
jagsData <- list(N = N, y = data$y,
    URBAN = data$URBAN, SEN = data$SENIORITY, 
    AGE = data$AGE, MEN = data$MEN)
```

```{r}
m1_blogit <- jags(data=jagsData,model.file='models/m1_logit.bug',
                   param=c('beta0','beta_urban', 'beta_sen', 'beta_age', 'beta_men'),
                   n.chains=3, n.iter=20000, n.burnin=5000, n.thin=10)
```


```{r}
m1_blogit
```

```{r}
traceplot(m1_blogit)
```

```{r}
summary(jagsfit.mcmc)$statistics[, 'Mean']
```



```{r}
library(lattice)

jagsfit.mcmc <- as.mcmc(m1_blogit)
densityplot(jagsfit.mcmc)

HPDinterval(jagsfit.mcmc)
traceplot(jagsfit.mcmc)
```






### Acurácia Treino

Primeiramento tunamos o modelo para encontrar o melhor valor de mtry - número de variáveis amostradas aleatoriamente.
```{r}
t <- tuneRF(data_reg[,-1], data_reg[,1],
       stepFactor = 0.5,
       plot = TRUE,
       ntreeTry = 150,
       trace = TRUE,
       improve = 0.05)
```



```{r pressure, echo=FALSE}
rf <- randomForest(y~., data=data_reg, proximity=TRUE, mtry = 2) 
print(rf)
plot(rf)
```

```{r}
p1 <- predict(rf, data_reg)
cf_train <- caret::confusionMatrix(p1, data_reg$y)
cf_train
```

### Acurácia Teste

```{r}
p2 <- predict(rf, data_test)
cf_test <- caret::confusionMatrix(p2, data_test$y)
cf_test
```

```{r}
hist(treesize(rf),
     main = "No. of Nodes for the Trees",
     col = "green")
varImpPlot(rf,
           sort = T,
           n.var = 10,
           main = "Top 10 - Variable Importance")
importance(rf)
```

```{r}
partialPlot(rf, data_reg, SENIORITY, "1")
partialPlot(rf, data_reg, URBAN, "1")
partialPlot(rf, data_reg, MEN, "1")
partialPlot(rf, data_reg, PRIVATE, "1")
partialPlot(rf, data_reg, AGE, "1")

```

```{r}
MDSplot(rf, data_reg$y)
```

## Redes Neurais


```{r}
library(tensorflow)
library(keras)
set.seed(10727865)
```

```{r}

data_reg$y <- as.integer(data_reg$y)

data_reg %>% {
  cat(sprintf(
    "Número de indivíduos com cobertura completa de seguro: %s (%.2f%% of total)\n",
    nrow(filter(data_reg,y == 1)), 100*nrow(filter(data_reg,y == 1))/nrow(data_reg)))
}
```





