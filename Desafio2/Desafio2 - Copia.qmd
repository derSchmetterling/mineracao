---
title: "Desafio 2"
subtitle: "Predizendo probabilidade de adquirir aluguel para máquinas"
author: Pedro Vinícius Alves Silva - 10727865
format:
  html:
    embed-resources: true
    fontsize: 15pt
    theme: sandstone
    code-fold: true
    echo: true
    number-sections: false
    code-tools: true
    toc: true
    df-print: paged
editor: visual
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Bibliotecas

```{r bibliotecas, warning=FALSE, message=FALSE}

library(lares)
library(ggplot2)
library(dplyr)
library(readxl)
library(GGally)
library(gamlss)
library(nnet)
library(caret)
library(bamlss)
```

# Amostragem e divisão treino e teste

Procedimentos de amostragem e divisão de treino e teste estão disponíveis no arquivo .qmd.

```{r}
# data <-  read_excel('ChoiceBehaviour.xlsx')
# head(data)
```

```{r}
#| echo: false
# set.seed(10727865)
# sampled_df <- sample_n(data, 2000)
# write.csv(sampled_df,'baseprincipal.csv', sep = '/t', row.names = F)
# 
# sampled_df <- data.frame(sampled_df)
# 
# sampled_df[c(1,2),]
```

```{r}
#| echo: false
# train_idx <- caret::createDataPartition(sampled_df$Resposta, p =0.7, list = FALSE)
# 
# train_df <- sampled_df[train_idx,]
# test_df <- sampled_df[-train_idx,]
# 
# write.csv(train_df,'basetreino.csv', sep = '/t', row.names = F)
# 
# write.csv(test_df,'baseteste.csv', sep = '/t', row.names = F)
```

# Análise Exploratória

## Descrição do problema

Temos um conjunto de dados referentes ao aluguel de três máquinas por agricultores, as colunas são referentes a:

-   **Regiao:** variável discreta representando local onde moram os agricultores

-   **Prima:** variável discreta representando valor que o agricultor precisa pagar para reparar a máquina

-   **CustoProduto:** variável inteira positiva representando custo estimado do maquinário no momento do aluguel pelo agricultor

-   **Pmaquinabase:** variável contínua positiva representando o preço do aluguel da máquina base para dar cobertura ao assegurado

-   **Pmaquina1:** variável contínua positiva representando o preço do aluguel da máquina 1 ofertado ao agricultor

-   **Pmaquina2:** variável contínua positiva representando o preço do aluguel da máquina 2 ofertado ao agricultor

-   **Pmaquina3:** variável contínua positiva representando o preço do aluguel da máquina 3 ofertado ao agricultor

-   **Cmaquina1:** variável contínua positiva representando o custo do aluguel da máquina 1 ofertado ao agricultor

-   **Cmaquina2:** variável contínua positiva representando o custo do aluguel da máquina 2 ofertado ao agricultor

-   **Cmaquina3:** variável contínua positiva representando o custo do aluguel da máquina 3 ofertado ao agricultor

-   **Resposta:** variável discreta, assume o valor de 0 quando o agricultor não aluga nenhum máquina ou o número relativa a qual máquina ele alugou (1,2, ou 3).

O agricultor conhece apenas o valor de reparo das máquina (Prima) e o preço de aluguel de cada uma (Pmaquina1,Pmaquina2,Pmaquina3), enquanto a companhia tem conhecimento de todas as variáveis. **Assim, queremos construir um modelo que prediza qual máquina determinado agricultor vai alugar, desconsiderando aqueles clientes que não alugaram nenhuma.**

*Como não possuimos referências para saber qual a moeda na qual os preços são definidos, usamos o termo **unidades de moeda (u.m)** durante o trabalho.*

```{r}
complete_data <- read.csv('baseprincipal.csv')
data_train <-  read.csv('basetreino.csv')
data_test <-  read.csv('baseteste.csv')

complete_data <-  complete_data[,-1] %>% 
        mutate_at(vars(CustoProduto), as.integer) %>% 
        mutate_at(vars(Resposta, Regiao), as.factor) %>% 
        filter(Resposta != '0')


complete_data[,11] <- droplevels(complete_data[,11])


data_train <- data_train[,-1] %>% 
        mutate_at(vars(CustoProduto), as.integer) %>% 
        mutate_at(vars(Resposta, Regiao), as.factor) %>% 
        filter(Resposta != '0')

data_train[,11] <- droplevels(data_train[,11])



data_test <- data_test[,-1] %>% 
        mutate_at(vars(CustoProduto), as.integer) %>% 
        mutate_at(vars(Resposta,Regiao), as.factor) %>% 
        filter(Resposta != '0')

data_test[,11] <- droplevels(data_test[,11])


head(data_train)
data_train
```

Inicialmente vemos que não há valores faltantes nem no conjunto de treino nem no conjunto de teste

```{r, message=FALSE, warning=FALSE}
library(VIM)
aggr(data_test, col = c('green','red'), numbers = TRUE, sortVars = TRUE, 
     labels = names(data_train), cex.axis = .5, gap = 2, 
     ylab = c("Proportion in variable","Proportion in dataset"))
```

## Custos e Preços

Analisando rapidamente a média e a mediana dos preços, notamos que preços são próximos entre todas as máquinas, temos aproximadamente uma diferença de 50 a 100 u.m entre as possíveis escolhas. Assim, prosseguindo a análise, aplicamos o teste de Kruskal-Wallis para verificar se as distribuições de preço provém da mesma distribuição.

$$
H_0: \text{Os preços das máquinas provém da mesma distribuição}
$$

$$
H_1: \text{Os preços das máquinas não provém da mesma distribuição}
$$

```{r, warning=FALSE}
summary(data_train[, c('Pmaquina1', 'Pmaquina2', 'Pmaquina3' )])
```

Assumindo um nível de significância de 5%, não rejeitamos a hipótese nula de que as distribuições são semelhantes.

```{r, warning=FALSE}
# ks.test(data_train$Pmaquina1, data_train$Pmaquina2 )
# ks.test(data_train$Pmaquina1, data_train$Pmaquina3 )
# ks.test(data_train$Pmaquina2, data_train$Pmaquina3 )

c1 <- unlist(data_train['Pmaquina1'], use.names = FALSE)
c2 <- unlist(data_train['Pmaquina2'], use.names = FALSE)
c3 <- unlist(data_train['Pmaquina3'], use.names = FALSE)


data <- c(c1,c2,c3)
factors <- c(rep('1', 144), rep('2', 144),rep('3', 144))

kruskal.test(data, factors)
```

Analogamente, os custos são em média semelhantes entre as máquinas.

```{r}
summary(data_train[, c('Cmaquina1', 'Cmaquina2', 'Cmaquina3' )])
```

```{r, warning=FALSE}
# ks.test(data_train$Cmaquina1, data_train$Cmaquina2 )
# ks.test(data_train$Cmaquina1, data_train$Cmaquina3 )
# ks.test(data_train$Cmaquina2, data_train$Cmaquina3 )


c1 <- unlist(data_train['Cmaquina1'], use.names = FALSE)
c2 <- unlist(data_train['Cmaquina2'], use.names = FALSE)
c3 <- unlist(data_train['Cmaquina3'], use.names = FALSE)


data <- c(c1,c2,c3)
factors <- c(rep('1', 144), rep('2', 144),rep('3', 144))

kruskal.test(data, factors)
```

Outro fator relevante, é que as variável *Pmaquinabase* e *Cmaquina2* possuem os mesmo valores, tratando de colunas duplicadas.

```{r}


sum(data_train['Pmaquinabase'] == data_train['Cmaquina2']) == nrow(data_train)
```

Assim, uma análise preliminar indica que, em média, o preço e o custos das máquinas não parece diferir. Logo, a adição de apenas uma dessas características deve ser suficiente para ajustar o modelo.

## Seleção de Features

### Correlações

Analisando a correlação linear entre as variáveis numéricas, notamos que as variáveis relativas ao custo das máquinas e o preço do aluguel estão fortemente relacionadas, como é de se esperar. Porém, é importante ressaltar como o custo de uma máquina está intimamente correlacionado com o preço de aluguel de outra ([*Pmaquina3*]{.underline} e *Cmaquina1* tem 0.82, por exemplo).

As variáveis *CustoProduto* e *Prima* foram as que apresentaram menor correlação com as outras, com coeficientes de menores ou iguais a 0.6, porém todas as correlações são estatisticamente diferentes de 0 ao nível de 5% de significância.

```{r}
#numeric <- c("AGE", "SENIORITY")
df_pearson<- data_train[, -c(1,11)]


correl<- cor(df_pearson, method = 'pearson')

testRes = corrplot::cor.mtest(df_pearson, conf.level = 0.95, method = 'pearson')

corrplot::corrplot(correl, p.mat = testRes$p, addCoef.col ='black',method = 'square', order = 'FPC', type = 'lower', insig = 'blank', number.cex=0.6)
```

Usando o coeficiente de Kendall e adicionando as covariáveis categóricas, nota-se como a *Regiao* tem correlação estatisticamente igual a zero com todas as outras covariáveis. É interessante ver também que *Cmaquina3 e Pmaquina1* não apresentam correlação com a variável Resposta e, de modo, geral, todas as covariáveis tem correlação monotônica fraca com a variável dependente.

```{r, warning=FALSE}

df_spearman <- data_train %>% 
  mutate_at(vars(Resposta), as.integer)

correl<- cor(df_spearman, method = 'kendall')

testRes = corrplot::cor.mtest(df_spearman, conf.level = 0.95, method = 'spearman')

corrplot::corrplot(correl, p.mat = testRes$p, addCoef.col ='black',method = 'square', order = 'FPC', type = 'lower', insig = 'blank', number.cex=0.6)
```

### ANOVA F-Score

Em seguida, utilizamos F-Score para escolher um conjunto de três variáveis para representar o conjunto de dados completo.

```{python}
import pandas as pd
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif


df = pd.read_csv('basetreino.csv')
df = df[df['Resposta'] != 0]

df['CustoProduto'] = df['CustoProduto'].astype(int)
df = df.drop('Id', axis = 1)
df['CustoProduto'] = df['CustoProduto'].astype(str).apply(lambda x: x[:-2])


```

```{python}

import matplotlib.pyplot as plt


fig = plt.figure()


ax = plt.axes(projection='3d')

# Data for a three-dimensional line

ax.scatter3D(xs = df['CustoProduto'].astype(float), ys= df['Prima'].astype(float), zs = df['Pmaquinabase'], c = df['Resposta'],  cmap = 'Greens')


df['CustoProduto']


plt.show()


```

```{python}

x = df.iloc[:,1:10]
y = df.iloc[:,10]


fs = SelectKBest(score_func=f_classif, k=3)
# aplica o método
X_selected = fs.fit_transform(x, y)
print('Features selecionadas: ')
fs.get_feature_names_out()
```

```{python}
col_names = ['Prima', 'Pmaquina2', 'Pmaquina3']
df_reduced = pd.DataFrame(X_selected, columns = col_names )
```

Vimos anteriormente também que *Pmaquina1,* Pmaquina*2*, *Pmaquina3* tem um correlação linear alta de acima de 0.9, então usaremos arbitrariamente apenas *Pmaquina1*, terminando com o seguinte conjunto de dados:

```{r}
# df_reg <- data_train %>% 
#   dplyr::select(c('Resposta', 'Pmaquina1', 'Prima'))
# 
# df_test <- data_test %>% 
#   dplyr::select(c('Resposta', 'Pmaquina1', 'Prima'))
# 
# 
# head(df_reg)

```

### Clusterização

Para termos uma ideia do perfil dos clientes, vamos aplicar um procedimento de agrupamento. Para isso, escalamos os dados númericos para que diferentes dimensões não afetem a análise de processo.

```{python}
#| warning: false

import pandas as pd
from sklearn.feature_selection import SelectKBest
from sklearn.feature_selection import f_classif
from sklearn.preprocessing import StandardScaler

df_scaled = df.copy()
df_scaled.iloc[:,0:10] = StandardScaler().fit_transform(df_scaled.iloc[:,0:10])
df_scaled.head()
```

Aplicamos o agrupamento hierárquico usando o método 'ward'.

```{python}
from sklearn.cluster import AgglomerativeClustering

#complete


cluster = AgglomerativeClustering(n_clusters = 3,
distance_threshold=None,
compute_distances = True,
linkage='ward')
model = cluster.fit(df_scaled)

```

```{python}

df_cluster = df.copy()
df_cluster['HCluster'] = model.labels_.astype(str)
df_cluster.sort_values(by = 'HCluster', inplace=True)
df_cluster['CustoProduto'] = df_cluster['CustoProduto'].astype(int)


```

```{python}
import seaborn as sns
import matplotlib.pyplot as plt
sns.set_palette(sns.color_palette("tab10",4))
fig, ax = plt.subplots(1,2, figsize=(12,9))
fig.tight_layout(pad=6.0)

p1 = sns.scatterplot(data = df_cluster,y = 'Prima', x = 'Pmaquina1',
hue = 'HCluster',
ax = ax[0])
p1.set(title = 'Prima vs Pmaquina3',ylabel = 'Custo de Matéria Prima',xlabel = 'Preço da Máquina 1')

# p2 = sns.scatterplot(data = df_cluster,x = 'Prima', y = 'Pmaquina2',
# hue = 'HCluster',
# ax = ax[1])
# p2.set(title = 'Prima por Pmaquina3',xlabel = 'Custo de Matéria Prima',ylabel = 'Preço da Máquina 3')



p2 = sns.histplot(data = df_cluster,
x = 'Resposta',
hue = 'HCluster',
discrete = True,
multiple = 'stack',
ax = ax[1])
p2.set(title = 'Clusterização Hierárquica',
xlabel = 'Máquina Alugada',
ylabel = 'Frequência')



plt.show()
```

```{python}

from sklearn.cluster import KMeans
from sklearn.cluster import MiniBatchKMeans

cluster = KMeans(random_state = 10727865, n_clusters = 3, init = 'k-means++')
model_k = cluster.fit(df_scaled)


df_cluster['KMeans'] = model_k.labels_.astype(str)
df_cluster.sort_values(by = 'KMeans', inplace=True)
```

Ao plotar o custo de matéria prima e o preço da máquina 3 e analisando os agrupamentos gerados, conseguimos encontrar 3 grupos de clientes. Quando o preço da máquina 3 é alto, os clientes do grupo 1 parecem ter uma tendência maior a alugar a máquina 1. Analogamente, clientes do grupo 0, ao serem apresentados a um preço baixo da máquina 3, preferem alugar a máquina 2. Já os indivíduos do grupo 2, parecem ter uma preferência pelas máquinas 1 e 2, em detrimento da 3.

## Distribuição da Variável Resposta

Analisando a variável relativa ao aluguel de máquinas pelos agricultores, vemos que a grande maioria deles não alugou nenhuma.

```{r}
hist_resp <- ggplot(data_train %>% count(Resposta) %>%    
         mutate(pct=n/sum(n)),
       aes(as.factor(Resposta), n, fill = Resposta)) +
  geom_bar(stat="identity") +
  scale_fill_manual(values = c("#0072B2", "#D55E00", "#009E73"))+
  #geom_text(aes(label=paste0(sprintf("%1.1f", pct*100),"%")), position=position_stack(vjust=0.5)) +
  labs(x = 'Aluguel de Máquinas', y = 'Frequência Absoluta', title = "Distribuição de Resposta")

hist_resp
```

No total 144 indivíduos alugaram alguma das máquinas, sendo a máquina 2 a mais frequente.

```{r}
#n_diff_zero <- nrow(filter(data_train, Resposta != 0))
n_a1 <- nrow(filter(data_train, Resposta == 1))
n_a2 <- nrow(filter(data_train, Resposta == 2))
n_a3 <- nrow(filter(data_train, Resposta == 3))


train <- c(nrow(data_train),n_a1, n_a2, n_a3)



rent <-  data.frame(Alugadas = c(nrow(data_train),n_a1, n_a2, n_a3),
                    row.names = c('Total Alugadas','Alugou 1','Alugou 2', 'Alugou 3' ))

rent
```

### Resposta vs Custo

```{r}
hist_resp <- ggplot(data_train,
       aes(CustoProduto, Prima, colour = as.factor(Resposta) )) +
  geom_point(stat="identity") +
  #geom_text(aes(label=paste0(sprintf("%1.1f", pct*100),"%")), position=position_stack(vjust=0.5)) +
  scale_colour_manual(guide_legend(title="Máquina Alugada"), values = c("#0072B2", "#D55E00", "#009E73")) + 
  #scale_x_discrete(guide = guide_axis(n.dodge=3))+
  labs(y = 'Preço da Máquina 1', x = 'Custo de Matéria Prima', title = "Distribuição de Resposta")

hist_resp
```

```{r}
#knitr::knit_exit()
```

## 

### Visualizações 3D

```{r}
install.packages('rgl')
library(rgl)

data_plot <- data_train %>% 
  mutate_at(vars(Prima, CustoProduto), as.double)
mycolors <- c('royalblue1', 'darkcyan', 'red')
data_plot$color <- mycolors[ as.numeric(data_plot$Resposta) ]

# Plot
plot3d( 
  x=data_plot$CustoProduto, y=data_plot$Prima, z=data_plot$Pmaquinabase, 
  col = data_plot$color, 
  type = 'p', 
  radius = 10,
  size = 10,
  xlab="CustoProduto", ylab="Prima", zlab="Pmaquinabase", decorate = T)

plot


```

```{r}
library("RColorBrewer")
cols <- get_colors(data_plot$Resposta, brewer.pal(n=3, name="Dark2") )
rgl_init()
rgl.spheres(x=data_plot$CustoProduto, y=data_plot$Prima, z=data_plot$Pmaquinabase, r = 0.2, color = "blue") 
rgl_add_axes(x, y, z, show.bbox = TRUE)

?rgl_init
```

## Ajuste de Modelos

### Modelo Multinomial

Abaixo realizamos o ajuste de um modelo multinomial para predizer qual máquina os fazendeiros comprarão. Começamos com as covariáveis indicadas pela análise F-Score: *Pmaquina1* e *Prima*

```{r}

df_reg <- data_train

df_reg$Resposta2 <- relevel(df_reg$Resposta, ref = "1")
complete_data$Resposta2 <- relevel(complete_data$Resposta, ref = "1")


# df_reg$Pmaquina1 <- scale(df_reg$Pmaquina1)
# df_reg$Prima <- scale(df_reg$Prima)

m1 <- nnet::multinom(Resposta2 ~  Pmaquina1 + Prima, data = df_reg)

summary(m1)

#unique(predict(m1, newdata = reduced_data1, type = 'class'))


```

Além dos coeficientes, realizamos um teste de Wald para verificar a significância estatística dos coeficientes. Abaixo apresentamos os p-valores referentes.

```{r}
z <- summary(m1)$coefficients/summary(m1)$standard.errors

p <- (1 - pnorm(abs(z), 0, 1)) * 2
p
```

Verificamos que *Pmaquina1* não é significante nem no modelo da máquina 2 nem no modelo da máquina 3, enquanto *Prima* só é significante para o primeiro.

Em seguida, adicionamos as variáveis *CustoProduto*, *Pmaquinabase* e *Regiao* e removemos *Pmaquina1.*

```{r}
m1 <- nnet::multinom(Resposta2 ~ Prima + CustoProduto + Pmaquinabase + Regiao, data = df_reg)

summary(m1)
```

Aplicando o teste de Wald novamente:

```{r}
z <- summary(m1)$coefficients/summary(m1)$standard.errors

p <- (1 - pnorm(abs(z), 0, 1)) * 2
p
```

Vamos que todas as variáveis são estatisticamente significantes.

Podemos usar o modelo ajustado para e calcular seu potencial preditivo no conjunto de teste.

```{r}
preds_class <- predict(m1,type = 'class', newdata = data_test)
preds_score <- predict(m1,type = 'probs', newdata = data_test)

postResample(data_test$Resposta, preds_class)
multinom <- postResample(data_test$Resposta, preds_class)[[1]]
```

Em seguida, aplicamos um procedimento de validação cruzada para estimar a acurácia geral do modelo no conjunto de teste.

```{r, warning=FALSE, echo=FALSE, prompt=FALSE, results =FALSE}

# 
# totalAccuracy <- c()
# cv <- 10
# #cv <- 224
# cvDivider <- floor(nrow(data_train) / (cv+1))
# #cvDivider <- 50
# 
# for (cv in seq(1:cv)) {
#   # assign chunk to data test
#   dataTestIndex <- c((cv * cvDivider):(cv * cvDivider + cvDivider))
#   dataTest <- data_test[dataTestIndex,]
# 
#   # everything else to train
#   dataTrain <- complete_data[-dataTestIndex,]
#  
#   cylModel <-  nnet::multinom(Resposta2 ~ Prima + CustoProduto + Pmaquinabase + Regiao, data = dataTrain)
#  
#   pred <- predict(cylModel, newdata=dataTest, type="class")
#  
#   #  classification error
#   cv_ac <- postResample(dataTest$Resposta2, pred)[[1]]
#   print(paste('Current Accuracy:',cv_ac,'for CV:',cv))
#   totalAccuracy <- c(totalAccuracy, cv_ac)
# }
```

```{r}
# print(paste('Acurácia Modelo Multinomial: ', mean(totalAccuracy)) )
# multinom <- mean(totalAccuracy)
```

### Random Forest

Em seguida ajustamos um modelo RandomForest. Começamos ajustando os hiperparâmetros referente ao modelo e realizando um procedimento de validação cruzada no conjunto de treino. Usamos o mesmo conjunto de covariáveis selecionado no modelo multinomial (*Prima, CustoProduto, Pmaquinabase e Regiao*)

```{r, warning=FALSE, message=FALSE}
library(randomForest)

set.seed(10727865)
repeat_cv <- trainControl(method="cv", number=10, repeats=3, search="random")



tunegrid <- expand.grid(.mtry=9)

forest <- caret::train(
        
        # Formula. We are using all variables to predict Species
        Resposta~ Prima + CustoProduto + Pmaquinabase + Regiao, 
        
        # Source of data; remove the Species variable
        data=data_train, 
        
        # `rf` method for random forest
        method='rf', 
        
        # Add repeated cross validation as trControl
        trControl=repeat_cv,
        tuneLength = 10,
        tuneGrid = tunegrid,

        
        # Accuracy to measure the performance of the model
        metric='Accuracy')

## Print out the details about the model
rf_model <- forest$finalModel
rf_model
names(rf_model)
forest$coefnames
```

Abaixo apresentamos a acurácia no conjunto de teste.

```{r}
train_acc <- postResample(data_train$Resposta, rf_model$pred)
test_pred <- predict(forest, data_test)
postResample(data_test$Resposta, test_pred)

rf <- postResample(data_test$Resposta, test_pred)
```

A seguir, verificamos a importância (aqui definido como o decréscimo do índice de Gini a cada partição do modelo) das covariáveis na classificação do modelo.

```{r}
## Get variable importance, and turn into a data frame
var_imp <- varImp(forest, scale=FALSE)$importance
var_imp <- data.frame(variables=row.names(var_imp), importance=var_imp$Overall)

## Create a plot of variable importance
var_imp %>%
        
        ## Sort the data by importance
        arrange(importance) %>%
        
        ## Create a ggplot object for aesthetic
        ggplot(aes(x=reorder(variables, importance), y=importance)) + 
        
        ## Plot the bar graph
        geom_bar(stat='identity') + 
        
        ## Flip the graph to make a horizontal bar plot
        coord_flip() + 
        
        ## Add x-axis label
        xlab('Variables') +
        
        ## Add a title
        labs(title='Random forest variable importance') + 
        
        ## Some layout for the plot
        theme_minimal() + 
        theme(axis.text = element_text(size = 10), 
              axis.title = element_text(size = 15), 
              plot.title = element_text(size = 20), 
              )
```

Vemos que a Regiao é a característica menos relevante para a classificação. Assim, repetimos o procedimento de ajuste de hiperparâmetros sem essa covariável.

```{r}
forest <- caret::train(
        
        # Formula. We are using all variables to predict Species
        Resposta~ Prima + CustoProduto + Pmaquinabase, 
        
        # Source of data; remove the Species variable
        data=data_train, 
        
        # `rf` method for random forest
        method='rf', 
        
        # Add repeated cross validation as trControl
        trControl=repeat_cv,
        #tuneGrid = tunegrid,
        tuneLength = 6,
        
        # Accuracy to measure the performance of the model
        metric='Accuracy')

## Print out the details about the model
rf_model <- forest$finalModel

test_pred <- predict(forest, data_test)
postResample(data_test$Resposta, test_pred)

```

Vemos que com a retirada de *Regiao*, a acurácia do modelo sofre um decréscimo de 10%, logo não é viável retirá-la. Continuamos com o primeiro modelo de *RandomForest*.

### Modelo Multinomial Bayesiano

```{r}
## Model formula, each category may
## have different model terms.

library(bamlss)


## Rename levels.
levels(data_train$Resposta) <- paste0("L", levels(data_train$Resposta))
levels(data_test$Resposta) <- paste0("L", levels(data_test$Resposta))

## Response only in 1st formula.
f <- list(
  Resposta ~ Pmaquinabase + Prima + CustoProduto + Regiao,
           ~ Pmaquinabase + Prima + CustoProduto + Regiao
)

## Estimate.
b <- bamlss(f, family = "multinomial",
  data = data_train, reference = "L1" )



```

```{r}
summary(b)
```

```{r}
par(mfrow = c(1, 3), mar = c(4.1, 4.1, 0.1, 1.1))
plot(b)
```

```{r}
## Predict for the three levels.
p <- predict(b, newdata = data_test, type = "parameter")
```

```{r}
probs <- list()
for(j in names(p))
  probs[[j]] <- p[[j]] / (1 + rowSums(do.call("cbind", p)))
probs <- as.data.frame(probs)
probs[["L1"]] <- 1 - rowSums(probs)

probs <- probs[, c('L1', 'L2', 'L3')]

```

```{r}
probs1 <- probs %>% 
          mutate(max_prob = max.col(., ties.method = "last"),
          label =  as.integer(data_test[,'Resposta']))
```

```{r}
confusionMatrix(factor(probs1$max_prob),
                factor(probs1$label),
                mode = "everything")
```

```{r}
par(mar = c(4.1, 4.1, 1.1, 1.1))
plot2d(probs ~ Pmaquinabase + CustoProduto, data = data_test, col.lines = rainbow_hcl(4),
  lwd = 2, scheme = 1, ylab = "Fitted probabilities", ylim = c(0, 1))
legend("center", names(probs), lty = 1, lwd = 2, col = rainbow_hcl(4))
```

### XGBoost

Abaixo aplicamos um modelo de *ensemble* chamado de XGBoost. Analogamente ao RandomForest, temos a combinação de diversas árvores de decisão, porém aqui cada ajuste tem acesso aos resíduos do ajuste anterior, de forma que o modelo aprenda com as classificações errôneas.

```{r, warning=FALSE, message=FALSE}
#install.packages("xgboost")
library("xgboost")



xgb_data <- function(data){
  
  
   data$Resposta <- ifelse(data$Resposta == '1', 0, data$Resposta)
   data$Resposta <- ifelse(data$Resposta == '2', 1, data$Resposta)
   data$Resposta <- ifelse(data$Resposta == '3', 2, data$Resposta)
   
  data<- data %>%
    dplyr::select(c('Prima', 'Resposta', 'CustoProduto', 'Pmaquinabase', 'Regiao')) %>% 
    mutate_at(vars(Regiao), as.integer)
   
  data_variables <- as.matrix(data[!(names(data) %in% 'Resposta')])
  data_label <- as.integer(data[,'Resposta'])
  
  
  matrix_xgb <- xgb.DMatrix(data = data_variables, label = data_label)
  
  
  return(matrix_xgb)
  
}



train_matrix <- xgb_data(data_train)
test_matrix <- xgb_data(data_test)

```

Usamos também validação cruzada no conjunto de dados de treino para ajustar diversos modelos e selecionar os melhores hiperparâmetros.

```{r}

numberOfClasses <- length(unique(data_train$Resposta))
xgb_params <- list("objective" = "multi:softprob",
                   "eval_metric" = "merror",
                   "num_class" = numberOfClasses,
                   "booster" = 'dart',
                   "nrounds" = 50)
nround    <- 50 # number of XGBoost rounds
cv.nfold  <- 5

set.seed(10727865)


# Fit cv.nfold * cv.nround XGB models and save OOF predictions
cv_model <- xgb.cv(params = xgb_params,
                   data = train_matrix, 
                   nrounds = nround,
                   nfold = cv.nfold,
                   verbose = FALSE,
                   prediction = TRUE)

```

```{r}
OOF_prediction <- data.frame(cv_model$pred) %>%
  mutate(max_prob = max.col(., ties.method = "last"),
         label =  as.integer(data_train[,'Resposta']))
#head(OOF_prediction)

```

Temos uma acurácia de 0.52 no conjunto de teste para o melhor modelo ajustado. Vemos o desempenho no conjunto de teste.

```{r}
confusionMatrix(factor(OOF_prediction$max_prob),
                factor(OOF_prediction$label),
                mode = "everything")
```

Continuamos com o mesmo valor de 0.52 de acurácia no conjunto de teste.

```{r, warning=FALSE}
bst_model <- xgb.train(params = cv_model$params,
                       data = train_matrix,
                       nrounds = nround)

# Predict hold-out test set
test_pred <- predict(bst_model, newdata = test_matrix)
test_prediction <- matrix(test_pred, nrow = numberOfClasses,
                          ncol=length(test_pred)/numberOfClasses) %>%
  t() %>%
  data.frame() %>%
  mutate(label = as.integer(data_test[,'Resposta']),
         max_prob = max.col(., "last"))
# confusion matrix of test set
confusionMatrix(factor(test_prediction$max_prob),
                factor(test_prediction$label),
                mode = "everything")


xgboost <- confusionMatrix(factor(test_prediction$max_prob),
                factor(test_prediction$label),
                mode = "everything")$overall[[1]]


```

### 

### Support Vector Machine

```{r}

library(e1071) 
#install.packages('e1071')
svm1 <- svm(Resposta~  Prima + Pmaquinabase, data=data_train 
          , kernel="radial",
          gamma=5, cost=10, scale = F, type = 'nu-classification')
summary(svm1)
svm1$SV 

?svm
```

```{r}
plot(svm1, data_train, Pmaquinabase ~ Prima)
```

```{r}
prediction <- predict(svm1, data_test)
xtab <- table(data_test$Resposta, prediction)
xtab
```

```{r}
tune_out <- tune.svm(x = data_train[, c('Pmaquinabase', 'CustoProduto', 'Prima')], y = data_train[, 'Resposta'],  type = "C-classification", kernel = 'polynomial', degree = c(1,2,3,4), coef0 = c(1,2),
                     cost = c(.01), gamma = c(0.1), scale = FALSE)

?tune.svm
```

```{r}

#install.packages('MLmetrics')
library(MLmetrics)
# Setup for cross validation
ctrl <- trainControl(method="repeatedcv",   # 10fold cross validation
                     repeats=10,         # do 5 repetitions of cv
                     summaryFunction=multiClassSummary,   # Use AUC to pick the best model
                     classProbs=FALSE)

set.seed(42)
#Train and Tune the SVM
svm.tune <- train(x=data_train[, c('Pmaquinabase', 'Prima', 'CustoProduto')],
                  y= make.names(data_train[,'Resposta']),
                  method = "svmPoly",   # Radial kernel
                  tuneLength = 4, 
                  preProcess = c('center','scale'),
                   # Center and scale data
                  metric="Accuracy",
                  trControl=ctrl)


```

```{r}
pred <- predict(svm.tune, data_test, type = "prob") 
```

### One vs All

```{python}
#Import LogisticRegression() model from scikit_learn
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression#define dataset
import pandas as pd
 
df = pd.read_csv('basetreino.csv')
df = df[df['Resposta'] != 0]
x_train = df.loc[:,['Pmaquinabase', 'Prima', 'CustoProduto']]
y_train = df.loc[:, 'Resposta']

df_teste = pd.read_csv('baseteste.csv')
df_teste = df_teste[df_teste['Resposta'] != 0]
x_test = df_teste.loc[:,['Pmaquinabase', 'Prima', 'CustoProduto']]
y_test = df_teste.loc[:, 'Resposta']

Multiclass_model = LogisticRegression(multi_class='multinomial')#fit model
Multiclass_model.fit(x_train, y_train)#make final predictions
y_pred = Multiclass_model.predict(x_test)

y_pred.shape
```

## Bibliografia

**Predicting Multiple Discrete Values with Multinomials, Neural Networkds and the {nnet} Package**. AMUNATEGI, Manueal. Disponível em: https://amunategui.github.io/multinomial-neuralnetworks-walkthrough/index.html

https://stats.oarc.ucla.edu/r/dae/multinomial-logistic-regression/

https://rpubs.com/mharris/multiclass_xgboost

https://www.thearmchaircritic.org/tech-journal/build-a-multi-class-classification-neural-network-in-r-in-fifty-lines-of-code

https://www.hackerearth.com/practice/machine-learning/machine-learning-algorithms/beginners-tutorial-on-xgboost-parameter-tuning-r/tutorial/
